{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchy Metrics Analysis\n",
    "\n",
    "**Purpose**: Comprehensive analysis of hierarchical learning using graph-based metrics.\n",
    "\n",
    "**This notebook**:\n",
    "- âœ… Analyzes graph topology (compression, connectivity, branching)\n",
    "- âœ… Computes information-theoretic metrics (MI, entropy, constraint effectiveness)\n",
    "- âœ… Evaluates prediction readiness (fan-out analysis)\n",
    "- âœ… Tracks training dynamics (growth exponent, reusability trends)\n",
    "- âœ… Provides health scoring and actionable recommendations\n",
    "- âœ… Visualizes all metrics with publication-quality plots\n",
    "\n",
    "**15 Core Metrics**:\n",
    "1-3. Compression (ratios, pattern counts, effectiveness)\n",
    "4-6. Connectivity (reusability, coverage, branching)\n",
    "7-9. Information Theory (MI, entropy, constraint effectiveness)\n",
    "10. Prediction (fan-out)\n",
    "11-12. Context (alignment, diversity)\n",
    "13-14. Training Dynamics (growth, reusability trends)\n",
    "15. Co-occurrence Validation\n",
    "\n",
    "**After training**: Run this notebook to evaluate hierarchy health."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import hierarchy metrics tools\n",
    "from tools.hierarchy_metrics import (\n",
    "    # Main report generator\n",
    "    MetricsReport,\n",
    "    \n",
    "    # Individual analyzers\n",
    "    GraphAnalyzer,\n",
    "    InformationTheoryAnalyzer,\n",
    "    PredictionAnalyzer,\n",
    "    \n",
    "    # Configuration\n",
    "    MetricsConfig,\n",
    "    ThresholdConfig,\n",
    "    \n",
    "    # Visualization\n",
    ")\n",
    "\n",
    "from tools.hierarchy_metrics.visualization import (\n",
    "    plot_compression_ratios,\n",
    "    plot_pattern_counts,\n",
    "    plot_reusability_distribution,\n",
    "    plot_coverage_heatmap,\n",
    "    plot_mutual_information,\n",
    "    plot_entropy_progression,\n",
    "    plot_training_dynamics,\n",
    "    plot_prediction_fanout,\n",
    "    plot_health_summary,\n",
    "    plot_full_dashboard\n",
    ")\n",
    "\n",
    "from tools.hierarchy_metrics.export import DashboardExporter, export_for_web\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ All modules imported successfully\")\n",
    "print(\"âœ“ Ready for hierarchy metrics analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Analysis\n",
    "\n",
    "Point to the hierarchy graph database created during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to hierarchy graph database (created during training)\n",
    "GRAPH_DB_PATH = './metrics/hierarchy_graph.db'\n",
    "\n",
    "# Optional: Path to learner (for prediction analysis)\n",
    "# If you have a saved learner, load it here:\n",
    "# from tools import HierarchicalConceptLearner\n",
    "# learner = ...  # Load your learner\n",
    "learner = None  # Set to None to skip prediction analysis\n",
    "\n",
    "# Configuration\n",
    "config = MetricsConfig(\n",
    "    enable_training_collection=True,\n",
    "    checkpoint_interval=1000,\n",
    "    compute_mutual_information=True,\n",
    "    compute_pattern_diversity=True,\n",
    "    diversity_sample_size=1000,\n",
    "    prediction_test_size=100,\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Configuration loaded\")\n",
    "print(f\"  Graph DB: {GRAPH_DB_PATH}\")\n",
    "print(f\"  Prediction analysis: {'enabled' if learner else 'disabled'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Comprehensive Report\n",
    "\n",
    "This runs all analyzers and computes all 15 metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive metrics report\n",
    "print(\"Generating comprehensive metrics report...\\n\")\n",
    "\n",
    "report = MetricsReport.generate(\n",
    "    graph_db_path=GRAPH_DB_PATH,\n",
    "    learner=learner,\n",
    "    config=config,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Report generation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Display Summary\n",
    "\n",
    "Overall health scoring and key metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive summary\n",
    "print(report.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Health Dashboard\n",
    "\n",
    "Visual overview of hierarchy health across all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot overall health dashboard\n",
    "plot_health_summary(report, figsize=(14, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compression Metrics (1-3)\n",
    "\n",
    "Analyze how effectively the hierarchy compresses information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compression ratios across levels\n",
    "plot_compression_ratios(report, figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern count progression\n",
    "plot_pattern_counts(report, figsize=(12, 6), log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed compression metrics\n",
    "print(\"Compression Ratios:\")\n",
    "for pair, ratio in report.compression.compression_ratios.items():\n",
    "    health = report.compression.health_status.get(f\"compression_{pair}\")\n",
    "    print(f\"  {pair}: {ratio:.2f}x [{health.value}]\")\n",
    "\n",
    "print(\"\\nPattern Counts:\")\n",
    "for level, count in sorted(report.compression.pattern_counts.items()):\n",
    "    print(f\"  {level}: {count:,}\")\n",
    "\n",
    "print(\"\\nEffective Compression Rates:\")\n",
    "for level, rate in report.compression.effective_compression_rates.items():\n",
    "    print(f\"  {level}: {rate:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Connectivity Metrics (4-6)\n",
    "\n",
    "Analyze graph connectivity and pattern reusability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusability for each level\n",
    "for level in sorted(report.compression.pattern_counts.keys()):\n",
    "    if level in report.connectivity.reusability:\n",
    "        plot_reusability_distribution(report, level, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage heatmap\n",
    "plot_coverage_heatmap(report, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed connectivity metrics\n",
    "print(\"Reusability (Mean Parents):\")\n",
    "for level, stats in sorted(report.connectivity.reusability.items()):\n",
    "    health = report.connectivity.health_status.get(f\"orphan_{level}\")\n",
    "    print(f\"  {level}: {stats['mean_parents']:.2f} parents, orphan rate: {stats['orphan_rate']:.1%} [{health.value}]\")\n",
    "\n",
    "print(\"\\nCoverage:\")\n",
    "for pair, rate in sorted(report.connectivity.coverage.items()):\n",
    "    health = report.connectivity.health_status.get(f\"coverage_{pair}\")\n",
    "    print(f\"  {pair}: {rate:.1%} [{health.value}]\")\n",
    "\n",
    "print(\"\\nBranching Factors:\")\n",
    "for level, stats in sorted(report.connectivity.branching_factors.items()):\n",
    "    health = report.connectivity.health_status.get(f\"branching_{level}\")\n",
    "    print(f\"  {level}: mean={stats['mean_children']:.2f}, cv={stats['cv']:.2f} [{health.value}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Information-Theoretic Metrics (7-9)\n",
    "\n",
    "Analyze mutual information and constraint effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutual information and constraint effectiveness\n",
    "plot_mutual_information(report, figsize=(14, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy progression\n",
    "plot_entropy_progression(report, figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed information metrics\n",
    "print(\"Mutual Information:\")\n",
    "for pair, mi_value in sorted(report.information.mutual_information.items()):\n",
    "    health = report.information.health_status.get(f\"mi_{pair}\")\n",
    "    print(f\"  {pair}: {mi_value:.3f} bits [{health.value}]\")\n",
    "\n",
    "print(\"\\nConditional Entropy:\")\n",
    "for key, h_cond in sorted(report.information.conditional_entropy.items()):\n",
    "    print(f\"  {key}: {h_cond:.3f} bits\")\n",
    "\n",
    "print(\"\\nConstraint Effectiveness (Normalized MI):\")\n",
    "for pair, effectiveness in sorted(report.information.constraint_effectiveness.items()):\n",
    "    health = report.information.health_status.get(f\"effectiveness_{pair}\")\n",
    "    print(f\"  {pair}: {effectiveness:.1%} [{health.value}]\")\n",
    "\n",
    "print(\"\\nEntropy Progression:\")\n",
    "for level, H in sorted(report.information.entropy_progression.items()):\n",
    "    print(f\"  {level}: {H:.2f} bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Dynamics (13-14)\n",
    "\n",
    "Analyze how patterns grew during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dynamics plots\n",
    "if report.training_dynamics:\n",
    "    plot_training_dynamics(report, figsize=(16, 6))\n",
    "else:\n",
    "    print(\"No training dynamics data available (checkpoints not captured)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed training dynamics\n",
    "if report.training_dynamics:\n",
    "    dynamics = report.training_dynamics\n",
    "    \n",
    "    print(\"Training Dynamics Metrics:\")\n",
    "    print(f\"  Growth exponent: {dynamics.growth_exponent:.3f}\")\n",
    "    print(f\"  Growth RÂ²: {dynamics.growth_r_squared:.3f}\")\n",
    "    print(f\"  Reusability trend slope: {dynamics.reusability_trend_slope:.4f}\")\n",
    "    print(f\"  Checkpoints captured: {len(dynamics.checkpoints)}\")\n",
    "    \n",
    "    # Health assessment\n",
    "    growth_health = dynamics.health_status.get('growth_exponent')\n",
    "    trend_health = dynamics.health_status.get('reusability_trend')\n",
    "    \n",
    "    print(f\"\\n  Growth health: {growth_health.value}\")\n",
    "    print(f\"  Reusability trend health: {trend_health.value}\")\n",
    "else:\n",
    "    print(\"No training dynamics data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Prediction Analysis (10)\n",
    "\n",
    "Analyze prediction fan-out (requires learner)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction fan-out\n",
    "if report.prediction:\n",
    "    plot_prediction_fanout(report, figsize=(12, 6))\n",
    "else:\n",
    "    print(\"Prediction analysis not available (learner not provided)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed prediction metrics\n",
    "if report.prediction:\n",
    "    print(\"Prediction Fan-Out Statistics:\")\n",
    "    for level, stats in sorted(report.prediction.fanout_by_level.items()):\n",
    "        health = report.prediction.health_status.get(f\"fanout_{level}\")\n",
    "        print(f\"  {level}: mean={stats['mean']:.1f}, std={stats['std']:.1f}, range=[{stats['min']}, {stats['max']}] [{health.value}]\")\n",
    "else:\n",
    "    print(\"Prediction analysis not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Full Dashboard\n",
    "\n",
    "Plot all metrics in one comprehensive view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate full dashboard with all visualizations\n",
    "plot_full_dashboard(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export Results\n",
    "\n",
    "Export metrics for external analysis or web dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to JSON\n",
    "report.export_json('./metrics/metrics_report.json')\n",
    "print(\"âœ“ Exported JSON report\")\n",
    "\n",
    "# Export to CSV\n",
    "report.export_csv('./metrics/csv')\n",
    "print(\"âœ“ Exported CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for web dashboards (Plotly, Parquet, etc.)\n",
    "exporter = DashboardExporter(report)\n",
    "\n",
    "# Export all formats\n",
    "exporter.export_all(\n",
    "    output_dir='./metrics/dashboard',\n",
    "    formats=['plotly', 'json', 'csv']  # Add 'parquet' if pandas installed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Interpretation Guide\n",
    "\n",
    "### Health Status Colors:\n",
    "- ðŸŸ¢ **EXCELLENT**: Optimal performance, no action needed\n",
    "- ðŸŸ¢ **GOOD**: Healthy, minor improvements possible\n",
    "- ðŸŸ¡ **WARNING**: Review recommended, may impact performance\n",
    "- ðŸŸ  **POOR**: Action needed, significant issues detected\n",
    "- ðŸ”´ **CRITICAL**: Immediate attention required\n",
    "\n",
    "### Key Metrics Interpretation:\n",
    "\n",
    "**Compression Ratio**:\n",
    "- Target: ~chunk_size (e.g., 5-15x for typical configs)\n",
    "- Too low (<3x): Insufficient compression, increase chunk_size\n",
    "- Too high (>20x): May lose important distinctions\n",
    "\n",
    "**Orphan Rate**:\n",
    "- Target: <10%\n",
    "- High orphan rate: Increase training data or adjust chunk_size\n",
    "\n",
    "**Coverage**:\n",
    "- Target: >70%\n",
    "- Low coverage: Lower patterns not being reused effectively\n",
    "\n",
    "**Constraint Effectiveness**:\n",
    "- Target: 50-80%\n",
    "- Low (<30%): Upper levels not constraining lower levels\n",
    "- Too high (>90%): Over-deterministic, may reduce flexibility\n",
    "\n",
    "**Growth Exponent**:\n",
    "- Target: 0.5-0.7 (sublinear growth)\n",
    "- Linear (1.0): No compression benefit from hierarchy\n",
    "- Superlinear (>1.0): Problematic, too many unique patterns\n",
    "\n",
    "### Common Issues and Solutions:\n",
    "\n",
    "1. **High orphan rate + low coverage**:\n",
    "   - Solution: Increase training data\n",
    "   \n",
    "2. **Poor compression ratios**:\n",
    "   - Solution: Adjust chunk_size or add more levels\n",
    "   \n",
    "3. **Low constraint effectiveness**:\n",
    "   - Solution: Review hierarchy architecture, consider different chunk_size per level\n",
    "   \n",
    "4. **Linear growth exponent**:\n",
    "   - Solution: Increase chunk_size to encourage pattern reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### ðŸ” Deep Dive Analysis\n",
    "- Review specific patterns with high/low frequency\n",
    "- Inspect parent-child relationships in graph DB\n",
    "- Compare metrics across multiple training runs\n",
    "\n",
    "### ðŸŽ¯ Optimization\n",
    "Based on metrics, adjust:\n",
    "- `chunk_size`: Target compression ratio ~5-15x\n",
    "- `num_levels`: Ensure coverage >70% at each transition\n",
    "- `training_data`: Reduce orphan rate to <10%\n",
    "\n",
    "### ðŸ“Š Experimentation\n",
    "- Train with different configs\n",
    "- Use this notebook to compare results\n",
    "- Track improvements in health scores\n",
    "\n",
    "### ðŸŒ Dashboards\n",
    "- Use exported Plotly JSON for interactive web dashboards\n",
    "- Import Parquet files into data analysis tools\n",
    "- Build custom visualizations with exported data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
