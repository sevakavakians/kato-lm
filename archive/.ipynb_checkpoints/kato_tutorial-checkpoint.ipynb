{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KATO Comprehensive Tutorial\n",
    "\n",
    "Welcome to the complete guide to KATO (Knowledge Abstraction for Traceable Outcomes). This tutorial will teach you how to use KATO to learn patterns, make predictions, and build intelligent systems with complete transparency and explainability.\n",
    "\n",
    "## What is KATO?\n",
    "\n",
    "KATO is a deterministic AI system that:\n",
    "- Learns temporal sequences from observations\n",
    "- Makes predictions based on learned patterns\n",
    "- Processes text, vectors, and emotions together\n",
    "- Provides complete traceability for every decision\n",
    "- Maintains isolated sessions for different contexts\n",
    "\n",
    "## Tutorial Outline\n",
    "\n",
    "1. **Starting KATO Server** - Getting KATO running\n",
    "2. **Sessions and Configuration** - Creating isolated environments\n",
    "3. **Basic Hello World** - First patterns and predictions\n",
    "4. **Understanding Predictions** - Deep dive into prediction fields\n",
    "5. **Prediction Metrics** - Confidence, frequency, and thresholds\n",
    "6. **Working with Emotives** - Adding emotional context\n",
    "7. **Vector Data** - Numeric representations\n",
    "8. **Word2Vec Integration** - Semantic similarity\n",
    "9. **Learning Modes** - Manual vs automatic learning\n",
    "10. **Abstraction Chains** - Connecting multiple sessions\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Starting KATO Server\n",
    "\n",
    "First, we need to get KATO running. KATO runs in Docker containers to ensure consistent behavior across different environments.\n",
    "\n",
    "### Prerequisites\n",
    "- Docker and Docker Compose installed\n",
    "- KATO source code (available at the specified directory)\n",
    "\n",
    "### Starting the Server\n",
    "\n",
    "Open a terminal and navigate to the KATO directory, then run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run this in your terminal (not in Jupyter)\n",
    "# cd /path/to/kato\n",
    "# docker-compose up -d"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This starts several services:\n",
    "\n",
    "- **KATO Service** (Port 8000): The main KATO processor that handles your requests\n",
    "- **Storage Services**: Database systems that KATO uses to store patterns and manage sessions\n",
    "\n",
    "### Verify KATO is Running\n",
    "\n",
    "Let's check that KATO is healthy and ready to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# KATO server URL\n",
    "KATO_URL = \"http://localhost:8000\"\n",
    "\n",
    "def check_kato_health():\n",
    "    \"\"\"Check if KATO server is running and healthy\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{KATO_URL}/health\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            health_data = response.json()\n",
    "            print(\"‚úÖ KATO is healthy!\")\n",
    "            print(f\"   Status: {health_data.get('status')}\")\n",
    "            print(f\"   Service: {health_data.get('service_name', 'KATO')}\")\n",
    "            if 'uptime_seconds' in health_data:\n",
    "                print(f\"   Uptime: {health_data['uptime_seconds']} seconds\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå KATO health check failed: {response.status_code}\")\n",
    "            return False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"‚ùå Cannot connect to KATO. Make sure Docker containers are running.\")\n",
    "        print(\"   Run: docker-compose up -d\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking KATO health: {e}\")\n",
    "        return False\n",
    "\n",
    "# Check KATO health\n",
    "check_kato_health()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see \"‚úÖ KATO is healthy!\", you're ready to proceed! If not, make sure Docker is running and you've started the containers with `docker-compose up -d`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Sessions and Configuration\n",
    "\n",
    "KATO uses **sessions** to provide isolated environments for different contexts or users. Each session has its own:\n",
    "- Short-term memory (working memory)\n",
    "- Emotional state\n",
    "- Configuration settings\n",
    "\n",
    "### Session Configuration Options\n",
    "\n",
    "When creating a session, you can configure:\n",
    "\n",
    "- **`max_pattern_length`**: Controls auto-learning behavior\n",
    "  - `0`: Manual learning only (you control when to learn)\n",
    "  - `> 0`: Auto-learn when short-term memory reaches this size\n",
    "\n",
    "- **`recall_threshold`**: Prediction sensitivity (0.0 to 1.0)\n",
    "  - `0.0`: Return all possible predictions\n",
    "  - `1.0`: Only return perfect matches\n",
    "  - `0.1`: Good default for flexible matching\n",
    "\n",
    "Let's create our first session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_session(name, max_pattern_length=0, recall_threshold=0.1):\n",
    "    \"\"\"Create a new KATO session with specified configuration\"\"\"\n",
    "    session_config = {\n",
    "        \"name\": name,\n",
    "        \"max_pattern_length\": max_pattern_length,\n",
    "        \"recall_threshold\": recall_threshold\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{KATO_URL}/sessions\", json=session_config)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        session_data = response.json()\n",
    "        session_id = session_data['session_id']\n",
    "        print(f\"‚úÖ Created session: {name}\")\n",
    "        print(f\"   Session ID: {session_id}\")\n",
    "        print(f\"   Max pattern length: {max_pattern_length} {'(manual learning)' if max_pattern_length == 0 else '(auto-learn)'}\")\n",
    "        print(f\"   Recall threshold: {recall_threshold}\")\n",
    "        return session_id\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to create session: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "def get_session_info(session_id):\n",
    "    \"\"\"Get information about a session\"\"\"\n",
    "    response = requests.get(f\"{KATO_URL}/sessions/{session_id}\")\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to get session info: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Create our tutorial session\n",
    "tutorial_session = create_session(\n",
    "    name=\"Tutorial Session\",\n",
    "    max_pattern_length=0,      # Manual learning\n",
    "    recall_threshold=0.1       # Flexible matching\n",
    ")\n",
    "\n",
    "print(f\"\\nüìù We'll use session {tutorial_session} for the rest of this tutorial.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Session Isolation\n",
    "\n",
    "Each session is completely isolated. Let's demonstrate by creating multiple sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create additional sessions to show isolation\n",
    "user_a_session = create_session(\"User A\", max_pattern_length=0, recall_threshold=0.1)\n",
    "user_b_session = create_session(\"User B\", max_pattern_length=5, recall_threshold=0.3)  # Auto-learn\n",
    "\n",
    "print(\"\\nüîí Session Isolation:\")\n",
    "print(f\"   Tutorial: {tutorial_session}\")\n",
    "print(f\"   User A:   {user_a_session}\")\n",
    "print(f\"   User B:   {user_b_session}\")\n",
    "print(\"\\n   Each session has independent memory and configuration!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Hello World Example\n",
    "\n",
    "Now let's start working with KATO! We'll begin with a simple \"hello world\" example to understand how KATO learns patterns and makes predictions.\n",
    "\n",
    "### Making Observations\n",
    "\n",
    "KATO learns from **observations**. Each observation can contain:\n",
    "- **strings**: Text data (list of strings)\n",
    "- **vectors**: Numeric data (list of numeric vectors)\n",
    "- **emotives**: Emotional context (dictionary)\n",
    "\n",
    "Let's start with simple text observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def observe(session_id, strings=None, vectors=None, emotives=None):\n",
    "    \"\"\"Send an observation to KATO\"\"\"\n",
    "    observation = {\n",
    "        \"strings\": strings or [],\n",
    "        \"vectors\": vectors or [],\n",
    "        \"emotives\": emotives or {}\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{KATO_URL}/sessions/{session_id}/observe\", json=observation)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(f\"üì• Observed: {strings}\")\n",
    "        return result\n",
    "    else:\n",
    "        print(f\"‚ùå Observation failed: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "def get_stm(session_id):\n",
    "    \"\"\"Get the current short-term memory\"\"\"\n",
    "    response = requests.get(f\"{KATO_URL}/sessions/{session_id}/stm\")\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['stm']\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to get STM: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Start with our hello world example\n",
    "print(\"üåç Hello World Example\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Make our first observations\n",
    "observe(tutorial_session, strings=[\"hello\"])\n",
    "observe(tutorial_session, strings=[\"world\"])\n",
    "\n",
    "# Check what's in short-term memory\n",
    "stm = get_stm(tutorial_session)\n",
    "print(f\"\\nüß† Short-term Memory: {stm}\")\n",
    "print(f\"   Length: {len(stm)} observations\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KATO's Learning Behavior\n",
    "\n",
    "KATO has an important characteristic: **it cannot learn single symbols**. It needs at least two observations to form a pattern. Let's see what happens when we try to learn now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def learn(session_id):\n",
    "    \"\"\"Trigger learning from short-term memory\"\"\"\n",
    "    response = requests.post(f\"{KATO_URL}/sessions/{session_id}/learn\", json={})\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        pattern_name = result.get('pattern_name')\n",
    "        if pattern_name:\n",
    "            print(f\"üéì Learned pattern: {pattern_name}\")\n",
    "            return pattern_name\n",
    "        else:\n",
    "            print(\"üìö No pattern learned (need more observations)\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"‚ùå Learning failed: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "# Try to learn with just \"hello\", \"world\"\n",
    "print(\"\\nüéì Attempting to learn...\")\n",
    "pattern_name = learn(tutorial_session)\n",
    "\n",
    "if pattern_name:\n",
    "    print(f\"‚úÖ Successfully learned pattern: {pattern_name}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  KATO needs more observations to learn a pattern\")\n",
    "    print(\"   Let's add another observation...\")\n",
    "    \n",
    "    # Add a third observation\n",
    "    observe(tutorial_session, strings=[\"tutorial\"])\n",
    "    \n",
    "    # Check STM again\n",
    "    stm = get_stm(tutorial_session)\n",
    "    print(f\"\\nüß† Updated STM: {stm}\")\n",
    "    \n",
    "    # Try learning again\n",
    "    print(\"\\nüéì Attempting to learn again...\")\n",
    "    pattern_name = learn(tutorial_session)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Learned Patterns\n",
    "\n",
    "Once KATO learns a pattern, you can retrieve it by name. The pattern name is a unique identifier (hash) that KATO generates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def get_pattern(pattern_name):\n",
    "    \"\"\"Retrieve a learned pattern by name\"\"\"\n",
    "    # Note: This would require a pattern retrieval endpoint\n",
    "    # For now, we'll demonstrate the concept\n",
    "    print(f\"üîç Pattern {pattern_name} contains the learned sequence\")\n",
    "    print(\"   Patterns are stored with frequency counts and metadata\")\n",
    "\n",
    "if pattern_name:\n",
    "    get_pattern(pattern_name)\n",
    "\n",
    "# Check STM after learning\n",
    "stm_after_learning = get_stm(tutorial_session)\n",
    "print(f\"\\nüß† STM after learning: {stm_after_learning}\")\n",
    "print(\"   Notice: STM is cleared after successful learning!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Predictions\n",
    "\n",
    "Now that we have a learned pattern, let's see how KATO makes predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def get_predictions(session_id):\n",
    "    \"\"\"Get predictions from KATO\"\"\"\n",
    "    response = requests.get(f\"{KATO_URL}/sessions/{session_id}/predictions\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to get predictions: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def print_predictions(predictions):\n",
    "    \"\"\"Pretty print predictions\"\"\"\n",
    "    if not predictions or 'predictions' not in predictions:\n",
    "        print(\"üîÆ No predictions available\")\n",
    "        return\n",
    "    \n",
    "    pred_list = predictions['predictions']\n",
    "    print(f\"üîÆ Found {len(pred_list)} prediction(s):\")\n",
    "    \n",
    "    for i, pred in enumerate(pred_list, 1):\n",
    "        print(f\"\\n   Prediction {i}:\")\n",
    "        print(f\"     Pattern: {pred.get('name', 'Unknown')}\")\n",
    "        print(f\"     Confidence: {pred.get('confidence', 0):.3f}\")\n",
    "        if 'future' in pred and pred['future']:\n",
    "            print(f\"     Future: {pred['future']}\")\n",
    "\n",
    "# Add some context and get predictions\n",
    "print(\"\\nüîÆ Getting Predictions\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Add some observations to create context\n",
    "observe(tutorial_session, strings=[\"hello\"])\n",
    "observe(tutorial_session, strings=[\"world\"])\n",
    "\n",
    "# Get predictions\n",
    "predictions = get_predictions(tutorial_session)\n",
    "print_predictions(predictions)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Concepts Summary\n",
    "\n",
    "From this basic example, we've learned:\n",
    "\n",
    "1. **Observations**: KATO learns from sequences of observations\n",
    "2. **Minimum Pattern Size**: KATO needs at least 2 observations to learn\n",
    "3. **Short-term Memory**: Working memory that holds recent observations\n",
    "4. **Learning**: Transfers patterns from STM to long-term storage\n",
    "5. **Predictions**: Based on current context and learned patterns\n",
    "6. **Pattern Names**: Unique identifiers for learned sequences\n",
    "\n",
    "Next, we'll explore predictions in much more detail!"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Level 2: Learn patterns of pattern names\\nprint(\\\"\\\\nüîó Level 2: Learning conversation flow patterns\\\")\\n\\n# Create conversation flow using pattern names as observations\\nclear_stm(level2_session)\\n\\n# Simulate typical conversation flow: greeting ‚Üí question ‚Üí farewell\\nfor category, pattern_name in patterns_learned:\\n    observe(level2_session, strings=[category])  # Use category names\\n    print(f\\\"   üì• Observed: {category} (represents {pattern_name[:20]}...)\\\")\\n\\nconversation_flow = learn(level2_session)\\nprint(f\\\"   ‚úÖ Conversation flow pattern: {conversation_flow}\\\")\\n\\n# Level 3: Learn meta-patterns about conversations\\nprint(\\\"\\\\nüß† Level 3: Learning meta-patterns\\\")\\n\\nclear_stm(level3_session)\\n\\n# Create different types of conversation flows\\nflow_types = [\\\"formal\\\", \\\"casual\\\", \\\"business\\\"]\\nfor flow_type in flow_types:\\n    observe(level3_session, strings=[flow_type])\\n    print(f\\\"   üì• Observed conversation type: {flow_type}\\\")\\n\\nmeta_pattern = learn(level3_session)\\nprint(f\\\"   ‚úÖ Meta conversation pattern: {meta_pattern}\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Create multiple sessions for abstraction chain\\nprint(\\\"üîó Building Abstraction Chains\\\")\\nprint(\\\"=\\\" * 30)\\n\\n# Level 1: Low-level pattern recognition\\nlevel1_session = create_session(\\\"Level 1 - Words\\\", max_pattern_length=0, recall_threshold=0.1)\\n\\n# Level 2: Pattern name recognition  \\nlevel2_session = create_session(\\\"Level 2 - Patterns\\\", max_pattern_length=0, recall_threshold=0.1)\\n\\n# Level 3: Meta-pattern recognition\\nlevel3_session = create_session(\\\"Level 3 - Meta\\\", max_pattern_length=0, recall_threshold=0.1)\\n\\nprint(\\\"\\\\nüìä Level 1: Learning basic word sequences\\\")\\n\\n# Learn several patterns in Level 1\\npatterns_learned = []\\n\\n# Pattern 1: Greeting sequence\\nclear_stm(level1_session)\\nobserve(level1_session, strings=[\\\"hello\\\"])\\nobserve(level1_session, strings=[\\\"there\\\"])\\nobserve(level1_session, strings=[\\\"friend\\\"])\\npattern1 = learn(level1_session)\\npatterns_learned.append((\\\"greeting\\\", pattern1))\\nprint(f\\\"   ‚úÖ Greeting pattern: {pattern1}\\\")\\n\\n# Pattern 2: Question sequence\\nclear_stm(level1_session)\\nobserve(level1_session, strings=[\\\"how\\\"])\\nobserve(level1_session, strings=[\\\"are\\\"])\\nobserve(level1_session, strings=[\\\"you\\\"])\\npattern2 = learn(level1_session)\\npatterns_learned.append((\\\"question\\\", pattern2))\\nprint(f\\\"   ‚úÖ Question pattern: {pattern2}\\\")\\n\\n# Pattern 3: Farewell sequence\\nclear_stm(level1_session)\\nobserve(level1_session, strings=[\\\"see\\\"])\\nobserve(level1_session, strings=[\\\"you\\\"])\\nobserve(level1_session, strings=[\\\"later\\\"])\\npattern3 = learn(level1_session)\\npatterns_learned.append((\\\"farewell\\\", pattern3))\\nprint(f\\\"   ‚úÖ Farewell pattern: {pattern3}\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Multiple Sessions and Abstraction Chains\n\nOne of KATO's most powerful features is the ability to chain multiple sessions together, creating abstraction layers where the output of one session becomes the input of another.\n\n### Creating Abstraction Chains",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Auto-learning demonstration\\nprint(\\\"\\\\nü§ñ Auto Learning Mode (max_pattern_length=3):\\\")\\nprint(\\\"   - Learns automatically when STM reaches max size\\\")\\nprint(\\\"   - STM is managed automatically\\\")\\nprint(\\\"   - Good for continuous data streams\\\")\\n\\nclear_stm(auto_session)\\nprint(\\\"\\\\n   Adding observations one by one...\\\")\\n\\nobserve(auto_session, strings=[\\\"auto\\\"])\\nprint(f\\\"   STM length: {len(get_stm(auto_session))} - no learning yet\\\")\\n\\nobserve(auto_session, strings=[\\\"learning\\\"])\\nprint(f\\\"   STM length: {len(get_stm(auto_session))} - no learning yet\\\")\\n\\nobserve(auto_session, strings=[\\\"mode\\\"])\\nprint(f\\\"   STM length: {len(get_stm(auto_session))} - triggered auto-learning!\\\")\\n\\n# The fourth observation should trigger learning and clear STM\\nobserve(auto_session, strings=[\\\"works\\\"])\\nprint(f\\\"   STM after auto-learn: {len(get_stm(auto_session))} - STM was cleared and new observation added\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demonstrate different learning modes\\nprint(\\\"‚öôÔ∏è Learning Modes Comparison\\\")\\nprint(\\\"=\\\" * 30)\\n\\n# Manual learning (max_pattern_length = 0)\\nmanual_session = create_session(\\\"Manual Learning\\\", max_pattern_length=0, recall_threshold=0.1)\\n\\n# Auto-learning (max_pattern_length = 3)\\nauto_session = create_session(\\\"Auto Learning\\\", max_pattern_length=3, recall_threshold=0.1)\\n\\nprint(\\\"\\\\nüìö Manual Learning Mode (max_pattern_length=0):\\\")\\nprint(\\\"   - You control when learning happens\\\")\\nprint(\\\"   - STM can grow indefinitely\\\")\\nprint(\\\"   - Call learn() explicitly\\\")\\n\\nclear_stm(manual_session)\\nobserve(manual_session, strings=[\\\"step\\\"])\\nobserve(manual_session, strings=[\\\"by\\\"])\\nobserve(manual_session, strings=[\\\"step\\\"])\\nprint(f\\\"   STM length: {len(get_stm(manual_session))} (no automatic learning)\\\")\\n\\nmanual_pattern = learn(manual_session)\\nprint(f\\\"   ‚úÖ Manual learning: {manual_pattern}\\\")\\nprint(f\\\"   STM after learning: {len(get_stm(manual_session))} (cleared)\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 9. Learning Modes and Advanced Features\n\nKATO offers different learning modes and configuration options that affect how and when patterns are learned.\n\n### Manual vs Automatic Learning",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test with semantically similar sentences\\nprint(\\\"\\\\nüîç Testing Semantic Similarity\\\")\\nprint(\\\"=\\\" * 32)\\n\\ndef test_semantic_prediction(session_id, test_sentence, description):\\n    \\\"\\\"\\\"Test prediction with a semantically similar sentence\\\"\\\"\\\"\\n    print(f\\\"\\\\n{description}\\\")\\n    print(f\\\"Test sentence: '{test_sentence}'\\\")\\n    \\n    clear_stm(session_id)\\n    words = test_sentence.lower().split()\\n    vectors = sentence_to_vectors(test_sentence, word_vectors)\\n    \\n    # Observe the test sentence\\n    for i, (word, vector) in enumerate(zip(words, vectors)):\\n        observe(session_id, strings=[word], vectors=[vector])\\n    \\n    predictions = get_predictions(session_id)\\n    \\n    if predictions and 'predictions' in predictions:\\n        print(\\\"üîÆ Semantic predictions:\\\")\\n        for pred in predictions['predictions']:\\n            print(f\\\"   Future: {pred.get('future', [])}\\\")\\n            print(f\\\"   Confidence: {pred.get('confidence', 0):.3f}\\\")\\n    else:\\n        print(\\\"‚ùå No semantic matches found\\\")\\n\\n# Test 1: Similar words (kitten ‚âà cat, sprint ‚âà run, quick ‚âà fast)\\ntest_semantic_prediction(semantic_session, \\n                        \\\"kitten sprint quick\\\", \\n                        \\\"üò∏ Test 1: Synonyms (kitten‚âàcat, sprint‚âàrun, quick‚âàfast)\\\")\\n\\n# Test 2: Different but related (puppy ‚âà dog, stroll ‚âà walk, sluggish ‚âà slow)\\ntest_semantic_prediction(semantic_session, \\n                        \\\"puppy stroll sluggish\\\", \\n                        \\\"üêï Test 2: Related words (puppy‚âàdog, stroll‚âàwalk, sluggish‚âàslow)\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Create a session for semantic learning\\nsemantic_session = create_session(\\\"Semantic Demo\\\", max_pattern_length=0, recall_threshold=0.2)\\n\\nprint(\\\"üß† Learning Semantic Patterns\\\")\\nprint(\\\"=\\\" * 30)\\n\\ndef learn_sentence_pattern(session_id, sentences, sentiment_spectrum=\\\"neutral-positive\\\", sentiment_value=0.5):\\n    \\\"\\\"\\\"Learn a pattern from sentences with semantic vectors and sentiment\\\"\\\"\\\"\\n    clear_stm(session_id)\\n    \\n    for sentence in sentences:\\n        words = sentence.lower().split()\\n        vectors = sentence_to_vectors(sentence, word_vectors)\\n        \\n        # Add sentiment based on sentence content\\n        emotives = {sentiment_spectrum: sentiment_value}\\n        \\n        observe(session_id, \\n               strings=words, \\n               vectors=vectors,\\n               emotives=emotives)\\n        \\n        print(f\\\"   üì• '{sentence}' ‚Üí {len(vectors)} vectors + sentiment {sentiment_value}\\\")\\n    \\n    pattern = learn(session_id)\\n    return pattern\\n\\n# Learn positive animal action patterns\\npositive_sentences = [\\n    \\\"cat run fast\\\",\\n    \\\"dog walk slow\\\"\\n]\\n\\npattern1 = learn_sentence_pattern(semantic_session, positive_sentences, \\\"sad-happy\\\", 0.7)\\nprint(f\\\"‚úÖ Learned positive pattern: {pattern1}\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Learning Semantic Patterns\n\nNow let's teach KATO patterns using word vectors, then test with semantically similar sentences:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Install required packages (run this once)\\n# !pip install gensim numpy\\n\\ntry:\\n    from gensim.models import Word2Vec\\n    from gensim.models import KeyedVectors\\n    print(\\\"‚úÖ Gensim imported successfully\\\")\\nexcept ImportError:\\n    print(\\\"‚ùå Please install gensim: pip install gensim\\\")\\n    print(\\\"   For this tutorial, we'll simulate word vectors\\\")\\n\\n# Create a simple word-to-vector mapping for demonstration\\n# In a real application, you'd use pre-trained models or train your own\\ndef create_simple_word_vectors():\\n    \\\"\\\"\\\"Create a simple word vector mapping for demonstration\\\"\\\"\\\"\\n    # Simplified word vectors (normally these would be 100-300 dimensions)\\n    word_vectors = {\\n        # Animals\\n        \\\"cat\\\": [0.8, 0.2, 0.9, 0.1],\\n        \\\"kitten\\\": [0.9, 0.3, 0.8, 0.2],  # Similar to cat\\n        \\\"dog\\\": [0.7, 0.4, 0.8, 0.3],\\n        \\\"puppy\\\": [0.8, 0.5, 0.7, 0.4],  # Similar to dog\\n        \\n        # Actions\\n        \\\"run\\\": [0.2, 0.8, 0.1, 0.7],\\n        \\\"sprint\\\": [0.3, 0.9, 0.2, 0.8],  # Similar to run\\n        \\\"walk\\\": [0.4, 0.6, 0.3, 0.5],\\n        \\\"stroll\\\": [0.5, 0.5, 0.4, 0.4],  # Similar to walk\\n        \\n        # Descriptors\\n        \\\"fast\\\": [0.1, 0.9, 0.2, 0.8],\\n        \\\"quick\\\": [0.2, 0.8, 0.3, 0.7],  # Similar to fast\\n        \\\"slow\\\": [0.8, 0.2, 0.7, 0.3],\\n        \\\"sluggish\\\": [0.9, 0.1, 0.8, 0.2],  # Similar to slow\\n    }\\n    return word_vectors\\n\\nword_vectors = create_simple_word_vectors()\\nprint(f\\\"üìö Created word vector mapping for {len(word_vectors)} words\\\")\\n\\n# Function to convert sentences to vector sequences\\ndef sentence_to_vectors(sentence, word_vectors):\\n    \\\"\\\"\\\"Convert a sentence to a sequence of word vectors\\\"\\\"\\\"\\n    words = sentence.lower().split()\\n    vectors = []\\n    for word in words:\\n        if word in word_vectors:\\n            vectors.append(word_vectors[word])\\n        else:\\n            # Unknown word - use zero vector\\n            vectors.append([0.0] * 4)\\n    return vectors\\n\\n# Test the conversion\\ntest_sentence = \\\"cat run fast\\\"\\nvectors = sentence_to_vectors(test_sentence, word_vectors)\\nprint(f\\\"\\\\nüî§ Sentence: '{test_sentence}'\\\")\\nprint(f\\\"üìä Vectors: {vectors}\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Word2Vec Integration - Semantic Similarity\n\nWord2Vec allows us to convert words into dense vector representations that capture semantic meaning. Words with similar meanings will have similar vectors, enabling KATO to recognize semantic patterns even when different words are used.\n\n### Installing and Using Word2Vec\n\nFirst, install the required dependencies (if not already done):",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Example 3: Rich multi-modal observations\\nprint(\\\"\\\\nüåà Example 3: Multi-Modal Data\\\")\\nprint(\\\"=\\\" * 35)\\n\\nclear_stm(vector_session)\\n\\n# Combine text descriptions, sensor data, and emotional context\\n# Scenario: Weather monitoring with user sentiment\\n\\n# Sunny morning - positive feeling\\nobserve(vector_session,\\n        strings=[\\\"sunny\\\", \\\"morning\\\"],\\n        vectors=[[25.0, 30.0, 1015.0]],  # temp, humidity, pressure\\n        emotives={\\\"sad-happy\\\": 0.8, \\\"calm-excited\\\": 0.3})\\n\\n# Rainy afternoon - negative feeling\\nobserve(vector_session,\\n        strings=[\\\"rainy\\\", \\\"afternoon\\\"],\\n        vectors=[[18.0, 85.0, 1008.0]],\\n        emotives={\\\"sad-happy\\\": 0.3, \\\"calm-excited\\\": 0.2})\\n\\n# Clear evening - peaceful feeling\\nobserve(vector_session,\\n        strings=[\\\"clear\\\", \\\"evening\\\"],\\n        vectors=[[22.0, 40.0, 1012.0]],\\n        emotives={\\\"sad-happy\\\": 0.7, \\\"calm-excited\\\": 0.1})\\n\\nprint(\\\"Multi-modal STM (text + vectors + emotions):\\\")\\nstm = get_stm(vector_session)\\nfor i, observation in enumerate(stm, 1):\\n    print(f\\\"   {i}. {observation}\\\")\\n\\nweather_pattern = learn(vector_session)\\nprint(f\\\"\\\\n‚úÖ Learned rich weather pattern: {weather_pattern}\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Combining Vectors with Text and Emotives\n\nThe real power comes from combining all three data types:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test with similar sensor readings\\nprint(\\\"\\\\nüîç Testing Vector Similarity\\\")\\nprint(\\\"=\\\" * 32)\\n\\n# Create context similar to learned pattern but with slight variations\\nclear_stm(vector_session)\\nobserve(vector_session, \\n        strings=[\\\"morning\\\"], \\n        vectors=[[21.2, 44.8, 1012.9]])  # Similar to original morning reading\\n\\nobserve(vector_session, \\n        strings=[\\\"noon\\\"], \\n        vectors=[[27.8, 39.1, 1011.5]])  # Similar to original noon reading\\n\\nprint(\\\"Context: Similar sensor readings with small variations\\\")\\nprint(f\\\"STM: {get_stm(vector_session)}\\\")\\n\\n# Get predictions - should match the learned sensor pattern\\npredictions = get_predictions(vector_session)\\nif predictions and 'predictions' in predictions:\\n    print(\\\"\\\\nüîÆ Predictions based on vector similarity:\\\")\\n    for i, pred in enumerate(predictions['predictions'], 1):\\n        print(f\\\"   Prediction {i}:\\\")\\n        print(f\\\"     Future: {pred.get('future', [])}\\\")\\n        print(f\\\"     Confidence: {pred.get('confidence', 0):.3f}\\\")\\n        print(f\\\"     Pattern: {pred.get('name', 'Unknown')[:20]}...\\\")\\nelse:\\n    print(\\\"\\\\n‚ùå No predictions returned\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Testing Vector Similarity\n\nLet's test how KATO matches similar vector patterns:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Example 2: Multi-dimensional sensor data\\nprint(\\\"\\\\nüå°Ô∏è Example 2: Sensor Data Sequence\\\")\\nclear_stm(vector_session)\\n\\n# Simulate temperature, humidity, pressure readings\\nobserve(vector_session, \\n        strings=[\\\"morning\\\"], \\n        vectors=[[20.5, 45.2, 1013.2]])  # temp, humidity, pressure\\n\\nobserve(vector_session, \\n        strings=[\\\"noon\\\"], \\n        vectors=[[28.1, 38.7, 1011.8]])\\n\\nobserve(vector_session, \\n        strings=[\\\"evening\\\"], \\n        vectors=[[23.6, 52.1, 1014.5]])\\n\\nprint(f\\\"Sensor STM: {get_stm(vector_session)}\\\")\\n\\nsensor_pattern = learn(vector_session)\\nprint(f\\\"‚úÖ Learned sensor pattern: {sensor_pattern}\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\\n\\n# Create a session for vector demonstrations\\nvector_session = create_session(\\\"Vector Demo\\\", max_pattern_length=0, recall_threshold=0.1)\\n\\nprint(\\\"üî¢ Working with Vector Data\\\")\\nprint(\\\"=\\\" * 30)\\n\\n# Example 1: Simple 2D coordinates\\nprint(\\\"\\\\nüìç Example 1: 2D Coordinate Sequence\\\")\\nclear_stm(vector_session)\\n\\n# Represent a path through 2D space\\nobserve(vector_session, strings=[\\\"start\\\"], vectors=[[0.0, 0.0]])\\nobserve(vector_session, strings=[\\\"move\\\"], vectors=[[1.0, 1.0]])\\nobserve(vector_session, strings=[\\\"turn\\\"], vectors=[[2.0, 1.0]])\\nobserve(vector_session, strings=[\\\"end\\\"], vectors=[[2.0, 2.0]])\\n\\nprint(f\\\"STM with vectors: {get_stm(vector_session)}\\\")\\n\\npath_pattern = learn(vector_session)\\nprint(f\\\"‚úÖ Learned path pattern: {path_pattern}\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Vector Data Integration - Numeric Representations\n\nKATO can process numeric vectors alongside text and emotions. Vectors allow you to represent data that doesn't fit well into discrete text categories, such as sensor readings, embeddings, coordinates, or any continuous numeric data.\n\n### Understanding Vectors in KATO\n\n- **Format**: Lists of numeric values (Python lists of floats)\n- **Size**: Can be any length, but consistency within patterns is important  \n- **Purpose**: Represent continuous, multi-dimensional data\n- **Matching**: KATO uses similarity measures to match vector patterns\n\n### Basic Vector Example",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Practical Applications of Emotives\n\nEmotives can represent many different types of contextual information:\n\n1. **Sentiment Analysis**: Track positive/negative sentiment in text\n2. **Confidence Levels**: Represent uncertainty in data or decisions\n3. **User States**: Model user mood, energy, or engagement\n4. **Environmental Context**: Represent external conditions affecting patterns\n5. **Quality Metrics**: Track quality, importance, or priority levels\n\n**Best Practices:**\n- Use **consistent spectrum naming** (negative-positive format)\n- Keep **values between 0.0 and 1.0**\n- Use **meaningful spectrum names** that reflect your domain\n- **Combine multiple spectrums** for rich contextual modeling\n- **Be consistent** with emotional assignments for similar contexts",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Multi-dimensional emotives example\\nprint(\\\"\\\\nüåà Multi-Dimensional Emotives Example\\\")\\nprint(\\\"=\\\" * 40)\\n\\n# Create complex emotional context\\nclear_stm(emotives_session)\\n\\n# Excited and happy announcement\\nmulti_emotives = {\\n    \\\"sad-happy\\\": 0.9,          # Very happy\\n    \\\"calm-excited\\\": 0.8,       # Very excited\\n    \\\"uncertain-confident\\\": 0.7  # Quite confident\\n}\\n\\nresult = observe(emotives_session, \\n                strings=[\\\"amazing\\\"], \\n                emotives=multi_emotives)\\nprint(\\\"üì• Observed 'amazing' with multi-dimensional context:\\\")\\nprint(f\\\"   sad-happy: {multi_emotives['sad-happy']} (very positive)\\\")\\nprint(f\\\"   calm-excited: {multi_emotives['calm-excited']} (high energy)\\\")\\nprint(f\\\"   uncertain-confident: {multi_emotives['uncertain-confident']} (confident)\\\")\\n\\n# Add more observations with similar emotional profile\\nobserve(emotives_session, \\n        strings=[\\\"breakthrough\\\"], \\n        emotives={\\\"sad-happy\\\": 0.85, \\\"calm-excited\\\": 0.9, \\\"uncertain-confident\\\": 0.8})\\n\\nobserve(emotives_session, \\n        strings=[\\\"discovered\\\"], \\n        emotives={\\\"sad-happy\\\": 0.8, \\\"calm-excited\\\": 0.7, \\\"uncertain-confident\\\": 0.9})\\n\\ncomplex_pattern = learn(emotives_session)\\nprint(f\\\"\\\\n‚úÖ Learned complex emotional pattern: {complex_pattern}\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Multi-Dimensional Emotives\n\nYou can use multiple emotive spectrums simultaneously to create rich contextual profiles:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Negative context test\\nprint(\\\"\\\\nüò¢ Scenario 2: Negative emotional context\\\")\\nclear_stm(emotives_session)\\nobserve_with_emotion(emotives_session, [\\\"hello\\\"], \\\"sad-happy\\\", 0.2, \\\"Sad greeting\\\")\\n\\npredictions = get_predictions(emotives_session)\\nif predictions and 'predictions' in predictions:\\n    print(\\\"Predictions with negative context:\\\")\\n    for i, pred in enumerate(predictions['predictions'], 1):\\n        print(f\\\"   Prediction {i}: {pred.get('future', [])}\\\")\\n        print(f\\\"     Confidence: {pred.get('confidence', 0):.3f}\\\")\\n        print(f\\\"     Pattern: {pred.get('name', 'Unknown')[:20]}...\\\")\\nelse:\\n    print(\\\"   No predictions returned\\\")\\n\\nprint(\\\"\\\\nüß† Notice how the emotional context influences which patterns match best!\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Test prediction with positive emotional context\\nprint(\\\"\\\\nüîÆ Testing Emotional Predictions\\\")\\nprint(\\\"=\\\" * 35)\\n\\n# Positive context test\\nprint(\\\"\\\\nüòä Scenario 1: Positive emotional context\\\")\\nclear_stm(emotives_session)\\nobserve_with_emotion(emotives_session, [\\\"hello\\\"], \\\"sad-happy\\\", 0.8, \\\"Happy greeting\\\")\\n\\npredictions = get_predictions(emotives_session)\\nif predictions and 'predictions' in predictions:\\n    print(\\\"Predictions with positive context:\\\")\\n    for i, pred in enumerate(predictions['predictions'], 1):\\n        print(f\\\"   Prediction {i}: {pred.get('future', [])}\\\")\\n        print(f\\\"     Confidence: {pred.get('confidence', 0):.3f}\\\")\\n        print(f\\\"     Pattern: {pred.get('name', 'Unknown')[:20]}...\\\")\\nelse:\\n    print(\\\"   No predictions returned\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Testing Emotional Context in Predictions\n\nNow let's see how emotional context affects KATO's predictions:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Negative context\\nclear_stm(emotives_session)\\nobserve_with_emotion(emotives_session, [\\\"hello\\\"], \\\"sad-happy\\\", 0.2, \\\"Sad greeting\\\")\\nobserve_with_emotion(emotives_session, [\\\"cruel\\\"], \\\"sad-happy\\\", 0.1, \\\"Very negative adjective\\\")\\nobserve_with_emotion(emotives_session, [\\\"world\\\"], \\\"sad-happy\\\", 0.3, \\\"Pessimistic view\\\")\\n\\npattern_negative = learn(emotives_session)\\nprint(f\\\"‚úÖ Learned negative pattern: {pattern_negative}\\\")\\n\\nprint(\\\"\\\\nüìä We now have two patterns with different emotional signatures!\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Create a session for emotives demonstration\\nemotives_session = create_session(\\\"Emotives Demo\\\", max_pattern_length=0, recall_threshold=0.1)\\n\\ndef observe_with_emotion(session_id, strings, emotion_spectrum, emotion_value, description=\\\"\\\"):\\n    \\\"\\\"\\\"Observe with emotional context\\\"\\\"\\\"\\n    emotives = {emotion_spectrum: emotion_value}\\n    result = observe(session_id, strings=strings, emotives=emotives)\\n    print(f\\\"   {description}: {emotion_spectrum}={emotion_value}\\\")\\n    return result\\n\\nprint(\\\"üòä Learning Patterns with Emotional Context\\\")\\nprint(\\\"=\\\" * 45)\\n\\n# Example: Hello world with different emotional contexts\\nprint(\\\"\\\\nüåç Teaching KATO about different 'hello world' contexts:\\\")\\n\\n# Positive context\\nclear_stm(emotives_session)\\nobserve_with_emotion(emotives_session, [\\\"hello\\\"], \\\"sad-happy\\\", 0.8, \\\"Positive greeting\\\")\\nobserve_with_emotion(emotives_session, [\\\"beautiful\\\"], \\\"sad-happy\\\", 0.9, \\\"Very positive adjective\\\")\\nobserve_with_emotion(emotives_session, [\\\"world\\\"], \\\"sad-happy\\\", 0.7, \\\"Optimistic view\\\")\\n\\npattern_positive = learn(emotives_session)\\nprint(f\\\"‚úÖ Learned positive pattern: {pattern_positive}\\\")\"\n   ]\n</invoke>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Working with Emotives - Adding Emotional Context\n\nEmotives in KATO provide emotional or contextual dimensions to your observations. They can represent sentiment, confidence, mood, or any other contextual information that affects pattern matching.\n\n### Understanding Emotive Spectrums\n\nKATO works best with **emotive spectrums** - pairs of opposing concepts connected by a hyphen:\n\n- **`sad-happy`**: Emotional sentiment spectrum\n- **`calm-excited`**: Energy level spectrum  \n- **`uncertain-confident`**: Confidence spectrum\n- **`negative-positive`**: General valence spectrum\n\nThe format is always: `negative_end-positive_end`\n\n### Basic Emotives Example",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Metrics Summary\n\nUnderstanding KATO's metrics helps you:\n\n1. **Trust Predictions**: Higher confidence = more reliable predictions\n2. **Filter Results**: Use recall thresholds to control prediction quality\n3. **Pattern Quality**: Frequency shows how well-established a pattern is\n4. **Distance Measures**: Hamiltonian distance quantifies pattern differences\n\n**Best Practices:**\n- Use **low thresholds (0.1-0.3)** for exploratory analysis\n- Use **high thresholds (0.7-0.9)** for production systems requiring reliability\n- **Monitor frequency** to understand pattern stability\n- **Compare confidence** across similar contexts to identify the best matches",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test with imperfect context to see threshold effects\ntest_context = [\\\"data\\\", \\\"research\\\"]  # \\\"research\\\" instead of \\\"science\\\"\n\nprint(\\\"\\\\nüîç Testing Recall Threshold Effects\\\")\nprint(\\\"Context: ['data', 'research'] (imperfect match)\\\\n\\\")\n\nfor session_id, name in zip(sessions, session_names):\n    clear_stm(session_id)\n    observe(session_id, strings=[\\\"data\\\"])\n    observe(session_id, strings=[\\\"research\\\"])\n    \n    predictions = get_predictions(session_id)\n    \n    print(f\\\"üìä {name} Session Results:\\\")\n    if predictions and 'predictions' in predictions and predictions['predictions']:\n        for pred in predictions['predictions']:\n            print(f\\\"   Confidence: {pred.get('confidence', 0):.4f}\\\")\n            print(f\\\"   Returned: Yes (above threshold)\\\")\\\n    else:\n        print(\\\"   No predictions returned (below threshold)\\\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Create sessions with different recall thresholds\nstrict_session = create_session(\\\"Strict Threshold\\\", recall_threshold=0.8)\nmoderate_session = create_session(\\\"Moderate Threshold\\\", recall_threshold=0.3)\npermissive_session = create_session(\\\"Permissive Threshold\\\", recall_threshold=0.0)\n\n# Learn the same pattern in all sessions\nsessions = [strict_session, moderate_session, permissive_session]\nsession_names = [\\\"Strict (0.8)\\\", \\\"Moderate (0.3)\\\", \\\"Permissive (0.0)\\\"]\n\nfor session_id, name in zip(sessions, session_names):\n    clear_stm(session_id)\n    observe(session_id, strings=[\\\"data\\\"])\n    observe(session_id, strings=[\\\"science\\\"])\n    observe(session_id, strings=[\\\"analysis\\\"])\n    learn(session_id)\n    print(f\\\"‚úÖ Learned pattern in {name} session\\\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Impact of Recall Threshold\n\nThe recall threshold filters predictions based on confidence. Let's see how different thresholds affect results:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Partial match scenario\nclear_stm(metrics_session)\nobserve(metrics_session, strings=[\\\"morning\\\"])\nobserve(metrics_session, strings=[\\\"tea\\\"])  # Different from learned \\\"coffee\\\"\n\npredictions = get_predictions(metrics_session)\nanalyze_prediction_metrics(predictions, \\\"Partial Match (Lower Confidence Expected)\\\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Test different confidence scenarios\nprint(f\\\"\\\\nüìä Pattern learned {len(patterns_learned)} times - higher frequency should increase confidence\\\")\n\n# Perfect match scenario\nclear_stm(metrics_session)\nobserve(metrics_session, strings=[\\\"morning\\\"])\nobserve(metrics_session, strings=[\\\"coffee\\\"])\n\npredictions = get_predictions(metrics_session)\nanalyze_prediction_metrics(predictions, \\\"Perfect Match (High Confidence Expected)\\\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Create a session specifically for metrics exploration\nmetrics_session = create_session(\"Metrics Demo\", max_pattern_length=0, recall_threshold=0.0)  # Very low threshold\n\ndef analyze_prediction_metrics(predictions_data, scenario_name):\n    \\\"\\\"\\\"Analyze and display prediction metrics\\\"\\\"\\\"\n    print(f\\\"\\\\nüìä {scenario_name} - Metrics Analysis\\\")\n    print(\\\"-\\\" * 50)\n    \n    if not predictions_data or 'predictions' not in predictions_data:\n        print(\\\"No predictions to analyze\\\")\n        return\n    \n    for i, pred in enumerate(predictions_data['predictions'], 1):\n        print(f\\\"\\\\n   Prediction {i}:\\\")\n        print(f\\\"     Confidence: {pred.get('confidence', 0):.4f}\\\")\n        print(f\\\"     Pattern: {pred.get('name', 'Unknown')[:20]}...\\\")\n        \n        # Show hamiltonian distance if available\n        if 'hamiltonian' in pred:\n            print(f\\\"     Hamiltonian Distance: {pred['hamiltonian']:.4f}\\\")\n        \n        # Show frequency if available\n        if 'frequency' in pred:\n            print(f\\\"     Pattern Frequency: {pred['frequency']}\\\")\n        \n        # Interpret confidence level\n        confidence = pred.get('confidence', 0)\n        if confidence > 0.8:\n            interpretation = \\\"üü¢ High confidence - Very reliable prediction\\\"\n        elif confidence > 0.5:\n            interpretation = \\\"üü° Medium confidence - Reasonably reliable\\\"\n        elif confidence > 0.2:\n            interpretation = \\\"üü† Low confidence - Use with caution\\\"\n        else:\n            interpretation = \\\"üî¥ Very low confidence - Uncertain prediction\\\"\n        \n        print(f\\\"     Interpretation: {interpretation}\\\")\n\nprint(\\\"üìà Learning Multiple Patterns for Metrics Analysis\\\")\nprint(\\\"=\\\" * 55)\n\n# Learn the same pattern multiple times to increase frequency\npatterns_learned = []\n\nfor i in range(3):\n    clear_stm(metrics_session)\n    observe(metrics_session, strings=[\\\"morning\\\"])\n    observe(metrics_session, strings=[\\\"coffee\\\"])\n    observe(metrics_session, strings=[\\\"routine\\\"])\n    pattern = learn(metrics_session)\n    if pattern:\n        patterns_learned.append(pattern)\n    print(f\\\"‚úÖ Learning iteration {i+1}: {pattern}\\\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Prediction Metrics - Understanding Confidence and Quality\n\nKATO provides several metrics to help you understand the quality and reliability of its predictions. Let's explore these in detail.\n\n### Key Metrics Explained\n\n1. **Confidence**: How certain KATO is about this prediction (0.0 to 1.0)\n2. **Hamiltonian Distance**: A measure of how different the current context is from the learned pattern\n3. **Frequency**: How many times this pattern has been learned\n4. **Recall Threshold**: The minimum confidence required to return a prediction\n\n### Exploring Confidence Scores",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Scenario 4: Understanding Past, Present, Future\nprint(\"\\\\nüéØ Scenario 4: Temporal Segmentation\")\nprint(\"-\" * 40)\n\n# Learn a second pattern to see temporal relationships\nclear_stm(prediction_session)\nobserve(prediction_session, strings=[\"red\"])\nobserve(prediction_session, strings=[\"car\"])\nobserve(prediction_session, strings=[\"drives\"])\nobserve(prediction_session, strings=[\"fast\"])\n\npattern2 = learn(prediction_session)\nprint(f\"‚úÖ Learned second pattern: {pattern2}\")\n\n# Now create a context that's in the middle of the first pattern\nclear_stm(prediction_session)\nobserve(prediction_session, strings=[\"the\"])\nobserve(prediction_session, strings=[\"quick\"])\n\nprint(f\"\\\\nCurrent context (middle of pattern): {get_stm(prediction_session)}\")\nprint(\"Analysis of temporal fields:\")\ndetailed_predictions(prediction_session)\n\nprint(\"\\\\nüìù Field Interpretation:\")\nprint(\"   - Past: What came before in the learned pattern\")\nprint(\"   - Present: Current observation context\")\nprint(\"   - Future: What KATO expects to come next\")\nprint(\"   - Matches: Parts of current context that match the pattern\")\nprint(\"   - Missing: Expected elements not seen in current context\")\nprint(\"   - Extras: Unexpected elements in current context\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Understanding Temporal Segmentation\n\nKATO segments time into past, present, and future based on your current context:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Scenario 3: Missing elements\nprint(\"\\\\nüéØ Scenario 3: Missing Elements\")\nprint(\"-\" * 35)\nclear_stm(prediction_session)\nobserve(prediction_session, strings=[\"the\"])\n# Skip \"quick\"\nobserve(prediction_session, strings=[\"brown\"])\n\nprint(f\"Current context: {get_stm(prediction_session)}\")\nprint(\"Expected: 'quick' should appear in 'missing' field\")\ndetailed_predictions(prediction_session)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Scenario 2: Partial match with extras\nprint(\"\\\\nüéØ Scenario 2: Partial Match with Extras\")\nprint(\"-\" * 40)\nclear_stm(prediction_session)\nobserve(prediction_session, strings=[\"the\"])\nobserve(prediction_session, strings=[\"quick\"])\nobserve(prediction_session, strings=[\"brown\"])\nobserve(prediction_session, strings=[\"unexpected\"])  # This wasn't in the original pattern\n\nprint(f\"Current context: {get_stm(prediction_session)}\")\nprint(\"Expected: 'unexpected' should appear in 'extras' field\")\ndetailed_predictions(prediction_session)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Scenario 1: Perfect match - recreate the exact sequence\nprint(\"\\\\nüéØ Scenario 1: Perfect Match\")\nprint(\"-\" * 30)\nclear_stm(prediction_session)\nobserve(prediction_session, strings=[\"the\"])\nobserve(prediction_session, strings=[\"quick\"])\nobserve(prediction_session, strings=[\"brown\"])\n\nprint(f\"Current context: {get_stm(prediction_session)}\")\nprint(\"Expected: KATO should predict 'fox', 'jumps'\")\ndetailed_predictions(prediction_session)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Testing Predictions with Partial Context\n\nNow let's test different scenarios to see how the prediction fields work:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create a new session for prediction examples\nprediction_session = create_session(\"Prediction Demo\", max_pattern_length=0, recall_threshold=0.1)\n\ndef clear_stm(session_id):\n    \"\"\"Clear short-term memory\"\"\"\n    response = requests.post(f\"{KATO_URL}/sessions/{session_id}/clear-stm\", json={})\n    if response.status_code == 200:\n        print(\"üßπ Cleared short-term memory\")\n        return True\n    else:\n        print(f\"‚ùå Failed to clear STM: {response.status_code}\")\n        return False\n\ndef detailed_predictions(session_id):\n    \"\"\"Get predictions with detailed field analysis\"\"\"\n    response = requests.get(f\"{KATO_URL}/sessions/{session_id}/predictions\")\n    \n    if response.status_code == 200:\n        predictions = response.json()\n        \n        if not predictions or 'predictions' not in predictions:\n            print(\"üîÆ No predictions available\")\n            return\n        \n        pred_list = predictions['predictions']\n        print(f\"üîÆ Found {len(pred_list)} detailed prediction(s):\")\n        \n        for i, pred in enumerate(pred_list, 1):\n            print(f\"\\nüìä Prediction {i} - Detailed Analysis:\")\n            print(f\"   Pattern Name: {pred.get('name', 'Unknown')}\")\n            print(f\"   Confidence: {pred.get('confidence', 0):.3f}\")\n            \n            # Temporal fields\n            if 'past' in pred:\n                print(f\"   Past: {pred['past']}\")\n            if 'present' in pred:\n                print(f\"   Present: {pred['present']}\")\n            if 'future' in pred:\n                print(f\"   Future: {pred['future']}\")\n            \n            # Match analysis fields\n            if 'matches' in pred:\n                print(f\"   Matches: {pred['matches']}\")\n            if 'missing' in pred:\n                print(f\"   Missing: {pred['missing']}\")\n            if 'extras' in pred:\n                print(f\"   Extras: {pred['extras']}\")\n                \n            # Additional metrics\n            if 'frequency' in pred:\n                print(f\"   Pattern Frequency: {pred['frequency']}\")\n    else:\n        print(f\"‚ùå Failed to get predictions: {response.status_code}\")\n\nprint(\"üìä Learning a Complex Sequence\")\nprint(\"=\"*40)\n\n# Create a longer, more interesting sequence\nclear_stm(prediction_session)\nobserve(prediction_session, strings=[\"the\"])\nobserve(prediction_session, strings=[\"quick\"])\nobserve(prediction_session, strings=[\"brown\"])\nobserve(prediction_session, strings=[\"fox\"])\nobserve(prediction_session, strings=[\"jumps\"])\n\nprint(f\"\\\\nüß† Current STM: {get_stm(prediction_session)}\")\n\n# Learn this pattern\nlearned_pattern = learn(prediction_session)\nprint(f\"\\\\n‚úÖ Learned pattern: {learned_pattern}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Understanding Predictions - Deep Dive into PredictionObject Fields\n\nKATO's predictions are rich objects with multiple fields that provide detailed information about what KATO expects to happen. Let's explore these fields with longer, more complex sequences.\n\n### Prediction Fields Explained\n\nEach prediction contains these key fields:\n\n- **`past`**: What KATO observed before the current context\n- **`present`**: The current context being used for prediction\n- **`future`**: What KATO predicts will come next\n- **`missing`**: Expected elements that weren't observed\n- **`matches`**: Elements that matched the learned pattern\n- **`extras`**: Unexpected elements that were observed\n- **`name`**: The unique identifier of the matching pattern\n- **`confidence`**: How confident KATO is in this prediction\n\n### Creating Complex Sequences\n\nLet's create longer sequences to see these fields in action:",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}